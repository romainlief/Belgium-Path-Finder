\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage[a4paper,left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{indentfirst}
\usepackage{appendix}
\usepackage{libertine}
\usepackage{titlesec}
\usepackage{eso-pic}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{caption}
\usepackage{color}
\usepackage{setspace}
\usepackage[T1]{fontenc}
\usepackage[hyphens]{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex}
\addbibresource{source.bib}\usepackage[linkbordercolor=white]{hyperref}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{bm}
\usepackage{enumitem}
\usepackage{siunitx}
\usepackage{textcomp}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{commath}
\usepackage{cancel}
\usepackage{pdflscape}
\usepackage{svg}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e} % Retain only one package
\usepackage{comment}
\usepackage{placeins}
\usepackage{listings}
\lstset{literate=%
    {à}{{\`a}}1 {â}{{\^a}}1 {é}{{\'e}}1 {è}{{\`e}}1 {ê}{{\^e}}1 {ë}{{\"e}}1 {î}{{\^i}}1 {ï}{{\"i}}1 {ô}{{\^o}}1 {ö}{{\"o}}1 {ù}{{\`u}}1 {û}{{\^u}}1 {ü}{{\"u}}1 {ç}{{\c{c}}}1 {Ç}{{\c{C}}}1{―}{{\textemdash}}1
    {’}{{'}}1 {‘}{{`}}1 {“}{{``}}1 {”}{{''}}1
}
\urlstyle{same}
\pagestyle{fancy}
\fancyhead[L]{\leftmark}
\fancyhead[R]{}
\renewcommand{\subsectionmark}[1]{}


\usepackage{titlesec}
\usepackage{hyperref}

\titleclass{\subsubsubsection}{straight}[\subsection]


\newcounter{subsubsubsection}[subsubsection]
\renewcommand\thesubsubsubsection{\thesubsubsection.\arabic{subsubsubsection}}
\renewcommand\theparagraph{\thesubsubsubsection.\arabic{paragraph}} % optional; useful if paragraphs are to be numbered


\titleformat{\subsubsubsection}
  {\normalfont\normalsize\bfseries}{\thesubsubsubsection}{1em}{}
\titlespacing*{\subsubsubsection}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{5}{\z@}%
  {3.25ex \@plus1ex \@minus.2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries}}
\renewcommand\subparagraph{\@startsection{subparagraph}{6}{\parindent}%
  {3.25ex \@plus1ex \@minus .2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries}}
\def\toclevel@subsubsubsection{4}
\def\toclevel@paragraph{5}
\def\toclevel@paragraph{6}
\def\l@subsubsubsection{\@dottedtocline{4}{7em}{4em}}
\def\l@paragraph{\@dottedtocline{5}{10em}{5em}}
\def\l@subparagraph{\@dottedtocline{6}{14em}{6em}}
\makeatother
\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}

\setlength{\headheight}{14.5pt}
\setlength{\parskip}{1em}
\renewcommand{\baselinestretch}{0.6}
\renewcommand{\headrulewidth}{1pt}
\newcommand{\HRule}{\rule{\linewidth}{0.3mm}}
\newcommand\BackgroundPic{%
	\put(0,0){%
		\parbox[b][\paperheight]{\paperwidth}{%
			\vfill
			\centering
			\includegraphics[width=\paperwidth,height=\paperheight,%
			keepaspectratio]{background.png}%
			\vfill}}}

% -----------------------------------------------------


\begin{document}
\AddToShipoutPicture*{\BackgroundPic}
\begin{titlepage}
  \begin{sffamily}
  \begin{flushleft} \large
    \includegraphics[height=2.0cm]{logo_ulb.jpg}
    \vspace{5cm}
   \end{flushleft}
  \begin{center}

    %Title
	\textsc{\huge INFO-F203 - Projet d'algorithmique 2}\\[1cm]

    \HRule \\[0.7cm]

	\textsc {\Huge Projet Mobilité}\\[0.4cm]

    \HRule \\[1.2cm]

% Author and supervisor
\begin{minipage}{0.5\textwidth}
\begin{flushleft} \large
\emph{Auteurs:}\\
Romain \textsc{Liefferinckx} - 000591790\\
Manuel \textsc{Rocca} - 000596086\\


\end{flushleft}
\end{minipage}


\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Professeurs:} \\
Jean  \textsc{Cardinal}\\
\emph{Assistants:} \\
Robin \textsc{Petit}
\end{flushright}
\end{minipage}


    \vfill

    %Bottom of the page
    {\large Année académique 2024-2025}
  \end{center}

  \end{sffamily}
\end{titlepage}


\clearpage


\tableofcontents

\newpage

% -----------------------------------------------------

\section{Introduction}
Dans le cadre de notre cours d'algorithmique INFO F-203, l'occasion s'est présentée à nous de créer un programme cherchant un chemin optimal
entre un point A et un point B sur base d'une heure de départ. En effet, sur base d'un ensemble de données
fournies sous format \emph{General Transit Feed Specification} (\textbf{GTFS}), nous avons utilisé le \emph{Connexion Scan Algorithm} (\textbf{CSA})
pour implémenter notre chercheur de chemin en \emph{Java}. 

Dans les sections à suivre, nous abordons l'initialisation des données, des structures formées à partir de celles-ci pour notre
implémentation et certains détails techniques comme la complexité temporelle et spatiale. Nous justifierons également certains choix
comme celui de l'algorithme précisé ci-dessus, à savoir le \textbf{CSA}.


\section{Initialisation des données}
\label{sec:init}
Dans cette section nous expliquons les procédés utilisés pour charger les données en mémoire à partir des fichiers CSV fournis ainsi que
les structures de données utilisées pour leur stockage et leur utilisation optimale dans l'algorithme choisi par nos soins.

Tout d'abord, décrivons brièvement la classe Parser, qui se charge de la lecture des fichiers CSV et de la création de dictionnaires (\emph{HashMap}) contenant les données chargées, faciles d'accès.
Nous avons créé, pour chaque type de fichier CSV, une classe de stockage qui contient les attributs correspondants aux champs du fichier CSV. Quelques subtilités notables au sujet de ces classes sont
décrites dans les sections suivantes.

\subsection{Objets de base pour le stockage}
Les fichiers CSV fournis contiennent des informations sur les arrêts, les trajets, les horaires et les routes de quatre entreprises de transport en commun,
à savoir la STIB en région Bruxelloise, TEC en région Wallone, DELIJN en région FLamande et, finalement, la SNCB pour le transport ferroviaire au niveau national.

Pour chaque type de fichier CSV, voici donc les classes correspondantes créées pour contenir les données de manière accessible.

\subsubsection{La classe Route}
\label{sec:route}
Cette classe est une simple classe de stockage, chaque attribut correspondant à un champ des fichiers \emph{routes.csv}.

% Table qui détaille la classe Route
\begin{table}[h]
    \centering
    \begin{tabular}{|l|l|p{8cm}|}
    \hline
    \textbf{Attribut} & \textbf{Type} & \textbf{Description} \\ \hline
    routeId & final String & L'identifiant de la route représentée \\ \hline
    routeShortName & final String & Le nom de la route raccourci \\ \hline
    routeLongName & final String & Le nom de la route complet \\ \hline
    routeType & final String & Le type de véhicule utilisant cette route \\ \hline
    \end{tabular}
    \caption{Classe Route}
\end{table}

\subsubsection{La classe StopTime}
\label{sec:stoptime}
La particularité de cette classe est qu'il lui manque l'identifiant de trajet donné dans les CSV concernés. Ce choix découle
de la structure de la classe Trip détaillée dans la section \hyperref[sec:trip]{2.1.4}.
% Table qui détaille la classe StopTime
\begin{table}[h]
    \centering
    \begin{tabular}{|l|l|p{8cm}|}
    \hline
    \textbf{Attribut} & \textbf{Type} & \textbf{Description} \\ \hline
    departureTime & final int & L'heure du départ à partir de
                                   l'arrêt associé sur le trajet associé en format 
                                   heure;minutes;secondes \\ \hline
    stopId & final String & L'identifiant de l'arrêt associé \\ \hline
    stopSequence & final int & Le numéro de l'arrêt dans le trajet associé \\ \hline
    \end{tabular}
    \caption{Classe StopTime}
\end{table}

\subsubsection{La classe Stop}
\label{sec:stop}
Dans cette classe, hormis le fait que chaque champ des fichiers \emph{routes.csv} est repris, nous avons fait le choix d'ajouter
une liste d'identifiants de trajet, permettant de retrouver efficacement chaque trajet partant de cet arrêt ainsi qu'une liste de \hyperref[sec:walk]{\emph{Walk}}, permettant
d'avoir un accès rapide à tous les arrêts accessibles à pied depuis cet arrêt.

Cette classe comprend également une méthode \emph{getDistanceToOther} qui permet de calculer la distance entre deux arrêts en utilisant la formule de Haversine,
implémentée dans une classe annexe, la classe \emph{Calculator}.

% Table qui détaille la classe Stop
\begin{table}[h]
    \centering
    \begin{tabular}{|l|l|p{8cm}|}
    \hline
    \textbf{Attribut} & \textbf{Type} & \textbf{Description} \\ \hline
    stopId & final String & L'identifiant du stop représenté \\ \hline
    stopName & final String & Le nom du stop \\ \hline
    stopLat & final String & La latitude du stop \\ \hline
    stopLon & final String & La longitude du stop \\ \hline
    tripIds & List$<$String$>$ & La liste des tous les trips (leurs identifiants) partant de ce stop \\ \hline
    walks & List$<$Walk$>$ & La liste de tous les arrêts accessibles à pied depuis ce stop \\ \hline
    \end{tabular}
    \caption{Classe Stop}
\end{table}

\subsubsection{La classe Trip}
\label{sec:trip}
Une fois de plus, en plus des champs trouvés dans les fichiers \emph{trips.csv} retranscrits en attribut, nous avons ajouté
une liste d'heures d'arrêt associées à ce trajet. Ceci nous permet de construire efficacement les connexions entre arrêts, affublées
de temps de départ et d'arrivée.

% Table qui détaille la classe Trip
\begin{table}[h]
    \centering
    \begin{tabular}{|l|l|p{8cm}|}
    \hline
    \textbf{Attribut} & \textbf{Type} & \textbf{Description} \\ \hline
    tripId & final String & L'identifiant du trip représenté \\ \hline
    routeId & final String & L'identifiant de la route sur laquelle il passe \\ \hline
    stopTimes & List$<$StopTime$>$ &  La liste de tous les StopTime associés à ce trip \\ \hline
    \end{tabular}
    \caption{Classe Trip}
\end{table}

\subsection{Création des structures de données}
Une fois les données lues et contenues dans des dictionnaires faciles d'accès (accès en temps constant), nous procédons à la création de structures de données
pertinentes à notre algorithme de recherche de chemin, le CSA à l'aide de la classe \emph{Builder}.

La classe \emph{Builder} est responsable de la création d'une liste de connexions entre arrêts, de la création du \emph{BallTree} utilisé pour construire efficacement les transferts à pied entre arrêts
et, finalement, la création de ces transferts à pied.

\subsubsection{La classe Connexion}
\label{sec:connexion}
L'algorithme CSA se base, comme son nom l'indique, sur des connexions entre les différents arrêts. Pour traiter cet aspect, nous avons fait le choix logique
d'implémenter une classe \emph{Connexion} \cite{dibbelt2017connection}.

\begin{table}[h]
    \centering
    \begin{tabular}{|l|l|p{8cm}|}
    \hline
    \textbf{Attribut} & \textbf{Type} & \textbf{Description} \\ \hline
    tripId & final String & L'identifiant du trajet utilisé par la connexion \\ \hline
    fromId & final String & L'identifiant de l'arrêt de de départ \\ \hline
    toId & final String &  L'identifiant de l'arrêt d'arrivée \\ \hline
    departureTime & final int & L'heure de départ de l'arrêt \emph{fromId} \\ \hline
    arrivalTime & final int & L'heure d'arrivée à l'arrêt \emph{toId} \\ \hline
    \end{tabular}
    \caption{Classe Trip}
\end{table}


\subsubsection{La classe BallTree}
\label{sec:balltree}
Afin de construire les transferts à pied (limités à une distance arbitraire), nous avons commencé par une implémentation brute-force en itérant, pour chaque arrêt, sur tous les
autres arrêts en $O(n^2)$, $n$ étant le nombre d'arrêts. Cependant, avec un total d'environ 65 000 arrêts, cette approche impliquait environ 4,5 milliards d'itérations avec, à chaque 
itération, une série d'opérations comme par exemple le calcul de la distance entre deux arrêts, en temps constant. Ceci nous a menés à un temps d'exécution d'environ 10 minutes sur nos 
machines rien que pour la création de ces transferts à pied, ce qui est, vous en conviendrez, absolument inacceptable.

Afin de remédier à ce problème critique, nous nous sommes penchés sur des structures de données plus adaptées à ce type de problème. Suite à une série de recherches et discussions avec
nos collègues, nous avons opté pour le \emph{BallTree}, une structure de données arborescente où chaque nœud représente une boule dans l'espace N-dimensionnel contenant un sous-ensemble d'arrêts.
Cette structure permet de récupérer efficacement les voisins d'un arrêt donné dans un rayon donné à l'aide de requêtes rapides \cite{BallTreedoc}.

\subsubsection{La classe Walk}
\label{sec:walk}
Classe simple, représentant un transfert à pied entre deux arrêts. Ces objets sont contenus sous forme de liste dans les arrêts correspondants \cite{dibbelt2017connection}.

\begin{table}[h]
    \centering
    \begin{tabular}{|l|l|p{8cm}|}
    \hline
    \textbf{Attribut} & \textbf{Type} & \textbf{Description} \\ \hline
    departure & final Stop & L'arrêt de départ du transfert à pied \\ \hline
    destination & final Stop & L'arrêt d'arrivée du transfert à pied \\ \hline
    duration & final int & La durée en secondes du transfert à pied \\ \hline
    \end{tabular}
    \caption{Classe Walk}
\end{table}

\newpage
\subsection{Complexité de l'initialisation}
Bien qu'étant une étape antérieure à l'exécution de l'algorithme, il reste important de discuter la complexité de cette étape. En effet, si nous avions choisi d'absolument ignorer
l'aspect de la complexité, nous aurions pu rester sur une implémentation brute-force, prenant 10 minutes à l'exécution. Bien entendu, pour éviter ces absurdités, nous avons apporté
un soin particulier à la création de ces structures de données.

\subsubsection{Complexité temporelle}
\label{sec:complexitetempinit}
L'initialisation des données se fait en plusieurs étapes, chacune ayant sa propre complexité. Premièrement, nous avons la lecture des fichiers CSV, qui a naturellement une complexité
linéaire $O(n)$, où $n$ est le nombre de lignes dans le fichier. 

Ensuite, pour la création des connexions, nous itérons dans tous les trajets et, pour chaque trajet, nous itérons dans leurs heures d'arrêts associés. Notons $n$ le nombre de trajets et $m$ le 
nombre d'arrêts associés à chaque trajet. La complexité de cette étape est donc $O(n \cdot m)$. Une fois la liste de connexions créée, nous procédons au tri de celle-ci en se basant sur 
l'heure de départ de chaque connexion à l'aide de l'algorithme de tri \emph{TimSort}, utilisé par \emph{Collections.sort()} \cite{javaTimSort}. Ceci se fait dans les pires et
moyen cas avec une complexité de $O(n \log n)$, où $n$ est le nombre de connexions avec un meilleur cas s'exécutant en $O(n)$ (si la liste est déjà majoritairement triée).

Finalement, le plus intéressant, la construction du \emph{BallTree} et des transferts à pied. La construction de notre \emph{BallTree} se fait de manière récursive, en divisant à chaque appel 
récursif l'ensemble des arrêts en deux sous-ensembles. Pour ce faire, des méthodes annexes comme \emph{FindFarthest} ou \emph{ComputeCenter} sont utilisées. Chacune d'entre elles s'exécute en 
temps linéaire, $O(n)$, où $n$ est le nombre d'arrêts dans l'ensemble de données. Quatres fonctions linéaires sont executées à chaque appel récursif, ce qui nous amène à une complexité de 
$4 * O(n)$, ce que nous pouvons résumer à $O(n)$. Finalement, concernant les appels récursifs, en supposant le partitionnement parfait, nous avons une profondeur d'arbre de $\log n$ et donc 
$O(n \log n)$ pour la construction de l'arbre complet \cite{BallTreedoc}.

Suite à quelques essais et tests, nous nous sommes rendu compte que le partitionnement n'est pas toujours optimal, cela étant probablement dû à la non-uniformité dans la répartition des arrêts à
travers la Belgique. Ceci nous permet de conclure, pour la complexité de la construction de notre \emph{BallTree}, que nous avons une complexité de $O(n \log n)$ dans le cas moyen ou optimal et de 
$O(n^2)$ dans le pire des cas. Cependant, ce dernier cas est très peu probable dans la pratique. En effet, la construction de l'arbre se fait en 400 millisecondes en moyenne sur nos machines, ce qui 
est tout à fait acceptable contrairement à l'implémentation brute-force environ 1500 fois plus lente avec un temps d'exécution de 10 minutes.

\begin{algorithm}[H]
    \footnotesize
    \SetAlgoNlRelativeSize{-1}
    \DontPrintSemicolon
    \KwIn{collection \texttt{stops}}
    \KwOut{racine d'un \texttt{BallTree} ou \texttt{null}}
    
    \If{\texttt{stops} est vide}{
      \Return \texttt{null}\;
    }
    \If{$|\texttt{stops}|\le\texttt{leafSize}$}{
      \Return \texttt{LeafNode}(\texttt{stops})\;
    }
    
    \tcp{Trouver deux pivots distants}
    $(p_1,p_2)\gets \texttt{FindFarthest}{\texttt{stops}}$\;
    
    \tcp{Partitionner selon la distance aux pivots}
    $\texttt{left}\gets\emptyset$, \quad $\texttt{right}\gets\emptyset$\;
    \ForEach{$s\in\texttt{stops}$}{
        \If{$\text{dist}(p_1,s) < \text{dist}(p_2,s)$}{
            $\texttt{left} \gets \texttt{left} \cup \{s\}$\;
        }  
      \Else{
        $\texttt{right}\gets \texttt{right}\cup\{s\}$\;
      }
    }
    
    \tcp{Calcul du centre et du rayon du nœud interne}
    $c\gets \texttt{ComputeCenter}{\texttt{stops}}$\;
    $r\gets \texttt{ComputeRadius}{\texttt{stops},\,c}$\;
    $node\gets \texttt{InternalNode}(c,r)$\;
    
    \tcp{Appels récursifs}
    $node.\mathit{left}\gets \texttt{BuildTree}{\texttt{left}}$\;
    $node.\mathit{right}\gets \texttt{BuildTree}{\texttt{right}}$\;
    
    \Return $node$\;
    \caption{BuildTree - Construction récursive d'un BallTree}
  \end{algorithm}
  
Une fois l'arbre construit, nous l'utilisons pour faire des requêtes pour trouver les arrêts à une distance donnée de tous les arrêts. Pour analyser la complexité d'une requête, nous allons considérer
plusieurs scénarios. Premièrement, dans un cas moyen voire optimal, à savoir quand la plupart des noeuds sont prunés (c'est-à-dire que plusieurs sous-arbres ne sont pas visités, améliorant ainsi l'efficacité
de la recherche) grâce à la condition \emph{distToCenter - node.radius > maxDist} et que l'arbre est bien équilibré, la complexité est sous-linéaire en $O(\log n + k)$, où $n$ est le nombre d'arrêts 
et $k$ le nombre d'arrêts trouvés dans la distance donnée. En revanche, comme abordé plus haut, nous nous devons de considérer le cas où l'arbre est déséquilibré et/ou que la plupart de noeuds ne sont 
pas prunés durant la recherche (la plupart des sous-arbres sont visités car le rayon de recherche est grand). Dans ce cas, la complexité de la recherche tend vers la linéarité (parcours de l'arbre au complet)
$O(n + k)$, où $n$ est le nombre d'arrêts et $k$ le nombre d'arrêts trouvés dans la distance donnée. Mais, une fois de plus, difficile d'arriver dans ce cas car la Belgique a une superficie de 30 528 km², une
distance Nord-Sud de 225 km et une distance Ouest-Est de 282 km. Additionnellement, le rayon de recherche que nous utilisons est de 500 mètres, ce qui est relativement faible par rapport à la taille de la Belgique,
nous obtenons une vitesse de requête de l'ordre de la 0,015 milliseconde (ce rayon est bien sûr changeable, mais nous avons considéré un rayon de transfert supposé acceptable pour la majorité de la population).

\begin{algorithm}[H]
    \footnotesize
    \SetAlgoNlRelativeSize{-1}
    \DontPrintSemicolon
    \KwIn{nœud \texttt{node}, requête \texttt{q}, distance max \texttt{maxDist}, collection \texttt{out}}
    \KwOut{ajoute dans \texttt{out} tous les stops à distance $\leq \texttt{maxDist}$ de \texttt{q}}
    
    \If{\texttt{node} = \texttt{null}}{
      \Return\;
    }
    
    \If{\texttt{node} est une feuille}{
      \ForEach{$s \in \texttt{node.stops}$}{
        \If{$\text{dist}(q,s) \le \texttt{maxDist}$}{
          \texttt{out} $\gets$ \texttt{out} $\cup \{s\}$\;
        }
      }
      \Return\;
    }
    $\texttt{distToCenter <-- dist(q, node.center)}$\;
    \If{$\texttt{distToCenter} - \texttt{node.radius} > \texttt{maxDist}$}{
      \Return\;  \tcp*{prune le sous-arbre}
    }
    
    \tcp{Sinon, nous explorons les deux sous-arbres}
    \text{\texttt{knn\_search}}(\text{\texttt{node.left}}, q, \text{\texttt{maxDist}}, \text{\texttt{out}})\;
    \text{\texttt{knn\_search}}(\text{\texttt{node.right}}, q, \text{\texttt{maxDist}}, \text{\texttt{out}})\;
\caption{\texttt{knn\_search} --- Recherche en rayon dans un BallTree}
\end{algorithm}

Pour construire les transferts à pied, nous itérons donc sur tous les arrêts et, pour chaque arrêt, nous récupérons tous ses voisins à grâce au \emph{BallTree} fraîchement construit. Ceci nous donne donc une complexité
linéaire pour la boucle principale $O(n)$, où $n$ est le nombre d'arrêts. Les requêtes de voisins ayant une complexité moyenne de $O(\log n + k)$, la construction des transferts à pied atteint une complexité totale de
$O(n\log(n + k))$ pour n arrêts et k arrêts trouvés dans la distance donnée.


\subsubsection{Complexité spatiale}
Chaque donnée des fichiers CSV est chargée en mémoire, impliquant une complexité spatiale de $O(n)$, où $n$ est le nombre de lignes total dans tous les fichiers réunis. Ensuite, les objets
comme les connexions, le \emph{BallTree} et les transferts à pied sont créés mais en utilisant les données initiales par référence. De ce fait, la complexité spatiale de ces objets se résume à leurs
données utiles (\emph{overhead}) et à la mémoire utilisée pour les références. En d'autres termes, la complexité spatiale de ces objets est très petite mais tout de même à considérer étant donné leur nombre.

Abordons maintenant un aspect de la complexité spatial qui n'est que `temporaire'. Le tri \emph{TimSort} utilise un espace supplémentaire de $O(n)$ pour le stockage temporaire des données pendant le tri uniquement.
La construction du \emph{BallTree} se faisant récursivement, il faut considérer les appels sur le stack. Ceux-ci dépendent en fonction de la taille des feuilles (le paramètre \emph{leafSize}). En effet, celui-ci
détermine le nombre maximal d'arrêts contenus sur une feuille. Plus ce nombre est grand, moins l'arbre sera grand et occupera d'espace en mémoire. En revanche les requêtes seront longues. D'autre part, plus ce nombre est petit,
plus nous augmentons le nombre d'appels récursifs (risquant ainsi un StackOverflowError qui fait planter le programme) et plus nous augmentons la taille de l'arbre et donc l'espace en mémoire tout en affinant la vitesse de
requêtes (note: une taille de feuille minimale ne signifie pas la vitesse de requête minimale). Voici un graphe pour illustrer ce propos:

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{images/feuille-nb-appels-récursifs.png}
    \caption{Nombre d'appels récursifs et temps de construction des transferts à pied en fonction de la taille des feuilles}
    % \label{fig:leafsize}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{images/average-query-time.png}
    \caption{Temps de requête moyen en fonction de la taille des feuilles}
    % \label{fig:leafsize}
\end{figure}


\newpage
\section{Le Connexion Scan Algorithm}
\label{sec:algorithme}
\subsection{Choix de l'algorithme}
Comme expliqué plus haut, pour résoudre le problème de recherche du plus court chemin, nous avons choisi d'implémenter le \emph{Connexion Scan Algorithm} (\textbf{CSA}).
Cet algorithme est particulièrement adapté pour les réseaux de transport en commun, car il permet de trouver rapidement le meilleur chemin
entre deux arrêts en tenant compte des horaires de départ et d'arrivée. Le CSA a été conçu spécifiquement pour traiter les problèmes de planification d'itinéraires 
dans les systèmes de transport en commun. Cependant, au travers de nos recherches, nous avons découvert des alternatives algorithmiques comme \emph{Dijkstra} ou \emph{A*}.
Nous jugeons donc important de justifier notre choix.

\subsubsection{Fonctionnement}
\textbf{CSA}: Basé sur une approche de recherche de chemin utilisant une liste triée de connexions entre arrêts, et parcourant ces connexions linéairement.
Plus précisément, l'algorithme parcourt les connexions dans un ordre croissant suivant les temps de départ, en mettant à jour les meilleurs temps d'arrivée à 
chaque arrêt  \cite{dibbelt2017connection}.


\textbf{Dijkstra}: Cherche le plus court chemin en partant du noeud de départ et en explorant tous les voisins, en choisissant toujours le chemin avec 
le coût total le plus faible. Il utilise une file de priorité pour gérer les noeuds à explorer \cite{dijkstra1959note}.

\textbf{A*}: Une amélioration de Dijkstra ayant la particularité d'utiliser une heuristique afin de guider la recherche vers la destination. Nécessitant une
heuristique optimale pour garantir la complétude et l'optimalité de l'algorithme. Celui-ci est donc plus rapide que Dijkstra à condition d'avoir une heuristique
correcte \cite{astart2021literature}.

\subsubsection{Facilité d'implémentation avec GTFS}
\textbf{CSA}: Essentiellement une simple itération sur les connexions.

\textbf{Dijkstra}: Nécessite de transformer les données de GTFS en graphe temporel (chaque arrêt devient un noeud).
Cette implémentation est moins naturelle que celle du CSA mais marche tout aussi bien \cite{dijkstra1959note}.

\textbf{A*}: En plus de la construction du graphe temporel, il est primordial de définir une heuristique efficace.

\subsubsection{Complexité}
\textbf{CSA}: $O(n)$, où $n$ est le nombre de connexions (de manière naïve). Très rapide en pratique pour les requêtes \emph{earliest arrival} grâce au tri temporel. 
Cependant, il demande un tri réalisé au préalable, durant l'initialisation des données, déjà expliqué en détail à la section \hyperref[sec:complexitetempinit]{2.3.1.}
Pour le cas du CSA, nous verrons après qu'il y a encore des optimisations possibles pour diminuer la complexité temporelle.

\textbf{Dijkstra}: $O((V + E) \log V)$, où $V$ est le nombre de noeuds et $E$ le nombre d'arêtes du graphe temporel.

\textbf{A*}: $O((V + E) \log V)$, mais dépend de la qualité de l'heuristique.

\subsubsection{Choix final}
Les algorithmes Dijkstra et A* utilisent donc des structures de données plus complexes comme des graphes temporels et des files de priorité. Ceci implique donc
un certain niveau de complexité supplémentaire dans l'implémentation.

Nous avons donc décidé de miser sur la simplicité d'implémentation et la rapidité de l'algorithme CSA, celui-ci
se basant essentiellement sur une liste de connexions triées. De plus, celui-ci est par défaut adapté aux fichiers GTFS et les horaires de transports publics \cite{linkGTFSCSA}.

\subsection{Explication et description de l'algorithme}
Le \emph{Connexion Scan Algorithm} est une méthode efficace pour résoudre les problèmes de planification d'itinéraires dans 
les réseaux de transports en commun basés sur des horaires, comme les trains et les bus. Contrairement aux algorithmes classiques 
qui utilisent une file de priorité (comme Dijkstra), le CSA se base sur une liste triée de tous les transports en commun, classés par 
leur heure de départ.

Il parcourt cette liste de manière séquentielle pour déterminer rapidement les meilleures connexions possibles pour atteindre une 
destination dans un délai optimal ou avec le moins de changements de véhicule.

\subsection{Structures de l'algorithme et implémentation}
L'algorithme est stocké dans une classe \emph{PathFinder} contenant la méthode findPath, qui implémente l'algorithme CSA.

\subsection{Pseudo-code sans la marche à pied et autres optimisations}
\begin{algorithm}[H]
  \footnotesize
  \SetAlgoNlRelativeSize{-1}
  \DontPrintSemicolon
  \KwIn{start, destination, time}
  \KwOut{Affiche le chemin optimal ou un message d'erreur}
  \tcp{La liste de connexions est triée par heure de départ préalablement durant le parsing}
  
  \ForEach{stopId dans tous les arrêts}{
    shortestPath[stopId] $\gets \infty$ \;
  }
  \ForEach{startingStop dans startingStops}{
    shortestPath[startingStop] $\gets$ userStartTime \;
  }
    
  \ForEach{connexion \texttt{c} dans \texttt{connexions}}{
      \If{\texttt{shortestPath[dep]} $\leq$ \texttt{depTime} \textbf{et} \texttt{shortestPath[arrive]} $>$ \texttt{arrTime}}{
          Mettre à jour \texttt{shortestPath[arrive]} et \texttt{previousConnection[arrive]} \;
      }
      \ForEach{walk depuis \texttt{depart}}{
          \If{\texttt{shortestPath[walkArr]} $>$ \texttt{walkTime}}{
              Mettre à jour \texttt{shortestPath[walkArr]} et \texttt{previousConnection[walkArr]} \;
          }
      }
  }

  \texttt{currentStop} $\gets$ \texttt{end\_stop} \;
  \While{\texttt{currentStop} dans \texttt{previousConnection}}{
      Ajouter la connexion à \texttt{path} au début \;
      \texttt{currentStop} $\gets$ origine de la connexion \;
  }
  
  \text{Afficher le chemin trouvé} \;
  
  \caption{CSA --- Recherche de chemin entre deux arrêts sans marche à pied}
  \end{algorithm}
    
\subsection{Complexité sans la marche à pied et autres optimisations}
Une fois l'initialisation des données terminée (cf. section \hyperref[sec:init]{2}), l'algorithme CSA est donc relativement direct à implémenter.
Il débute par le parcours de toutes les connexions une par une. Cette opération est naturellement linéaire, $O(n)$, où $n$ est le nombre de connexions.
Cette complexité est particulièrement avantageuse pour les grands ensembles de données, car elle permet un traitement efficace 
des requêtes après le prétraitement initial.

Tout ceci nous amène donc à une complexité totale de $O(n)$ pour la recherche de chemin, où $n$ est le nombre de connexions.

Notons tout de même le fait que cette complexité est valable uniquement dans le cas où nous ne considérons pas les transferts à pied, chose que nous
explicitons dans la section suivante.

\subsection{Pseudo-code avec la marche à pied et algorithme optimal}
\begin{algorithm}[H]
  \footnotesize
  \SetAlgoNlRelativeSize{-1}
  \DontPrintSemicolon
  \KwIn{startName, destinationName, userTime}
  \KwOut{Affiche le chemin optimal ou un message d'erreur}

  \ForEach{stopId dans tous les arrêts}{
    shortestPath[stopId] $\gets \infty$ \;
  }
  \ForEach{startingStop dans startingStops}{
    shortestPath[startingStop] $\gets$ userStartTime \;
  }

  bestArrivalTime $\gets \infty$   \tcp{Initialisation du meilleur temps d'arrivée}\;

  \tcp{Starting criterion}
  startIndex $\gets$ index de la première connexion avec depTime >= userStartTime (recherche dichotomique) \;

  \For{i $\gets$ startIndex \KwTo connexions.size()}{
    c $\gets$ connexions[i] \;
    \If{c.depTime > bestArrivalTime}{
      \textbf{break} \tcp*{Stopping criterion --- plus de chemin possible}
    }

    \If{shortestPath[c.dep] $\leq$ c.depTime \textbf{et} shortestPath[c.arr] $>$ c.arrTime}{
      shortestPath[c.arr] $\gets$ c.arrTime \;
      previousConnection[c.arr] $\gets$ c \;

      \If{c.arr $\in$ endStops \textbf{et} c.arrTime < bestArrivalTime}{
        bestArrivalTime $\gets$ c.arrTime \;
      }

      \ForEach{walk $\in$ walks depuis c.arr}{
        walkArr $\gets$ walk.destination \;
        walkTime $\gets$ c.arrTime + walk.duration \;
        \If{shortestPath[walkArr] $>$ walkTime}{
          shortestPath[walkArr] $\gets$ walkTime \;
          previousConnection[walkArr] $\gets$ \texttt{Connexion de type marche} \;
        }
      }
    }
  }

  \While{\texttt{currentStop} dans \texttt{previousConnection}}{
      Ajouter la connexion à \texttt{path} au début \;
      \texttt{currentStop} $\gets$ origine de la connexion \;
  }
  \text{Afficher le chemin trouvé} \;
  
  \caption{CSA --- Recherche de chemin avec critères d'arrêt et marches à pied}
\end{algorithm}


\subsection{Complexité avec la marche à pied et algorithme optimal}
Tel que mentionné précédemment, la complexité de l'algorithme principal est de l'ordre de $O(n)$, où $n$ représente le nombre de connexions. Mais, il n'est clairement pas logique
de considérer un voyage où nous ne marchons pas du tout. C'est pourquoi nous devons aussi traiter les transferts à pied. Lors de l'exécution de
l'algorithme, à chaque itération, autrement dit à chaque connexion, nous devons vérifier si l'arrêt de départ concerné possède des arrêts voisins à une distance
donnée (500 mètres dans notre cas, cf. \hyperref[sec:complexitetempinit]{2.3.1.}). Un transfert entre deux arrêts voisins est représenté comme un \emph{Walk}, une
classe décrite dans la section \hyperref[sec:walk]{2.2.3.}. Donc, pour chaque arrêt nous allons parcourons l'ensemble des transferts à pied disponibles.
En prenant $\bar{m}$ comme nombre moyen de transferts à pied moyen, nous avons une complexité totale de $O(n * \bar{m})$, avec $n$ étant toujours le nombre de connexions.

Nous pourrions croire que la complexité de l'algorithme avec les transferts à pied se rapproche de $O(n^2)$, mais ce n'est pas le cas. Pour répondre à cette incertitude,
nous avons tout simplement calculé la moyenne du nombre de transferts à pied par arrêt à l'aide d'un script Python. Ceci nous a menés à une valeur de 7 voisins dans un
rayon de 500 mètres par arrêt. Nous concluons donc que, avec un nombre de connexions étant de l'ordre de dizaines de millions, $\bar{m}$ est négligeable par rapport à $n$ et
nous arrivons à une complexité totale de $O(n)$.

\subsubsection{Optimisations}
Comme montré ci-dessus, l'algorithme n'est pas exactement linéaire. Nous avons donc décidé d'implémenter deux optimisations afin d'améliorer la vitesse de l'algorithme.
\begin{itemize}
    \item \textbf{Starting criterion:} Nous utilisons l'algorithme élémentaire qu'est la recherche dichotomique (en $O(\log n)$), pour trouver le premier arrêt 
    qui est supérieur ou égal à l'heure de départ. Ceci nous évite le parcours toutes les connexions en nous permettant de commencer à partir de l'indice trouvé.
    À travers ce procédé, nous réduisons le nombre d'itérations nécessaire pour trouver le chemin optimal. En effet, pour une requête de trajet débutant en fin
    de journée, pourquoi itérer dans les premières connexions ? Ceci est tout naturellement inutile. Grâce à cela, l'algorithme passe de $O(n)$ à $O(n - k)$ 
    avec $k$ le nombre de connexions avant l'heure de départ. La variable $k$ pouvant prendre des valeurs de $0$ à $n$, elle n'est pas négligeable dans le calcul
    de complexité totale. En conclusion, cela nous permet de grandement réduire le temps d'exécution de l'algorithme, et encore plus si l'heure de départ est
    élevée. Toutefois, si l'heure entrée par l'utilisateur est la première dans la liste de connexion, la complexité ne change pas et reste $O(n)$ car nous
    devons parcourir toutes les connexions.
    \item \textbf{Stopping criterion:} Cette seconde optimisation nous permet d'arrêter l'algorithme soit lorsque la destination atteinte, soit lorsque toutes 
    les connexions possibles ont été explorées. Cela nous éviter le parcours inutile des connexions qui ne contribuent pas à améliorer le chemin trouvé. 
    En pratique, dans le cas où l'heure d'arrivée à un arrêt est déjà optimale (c'est-à-dire qu'aucune connexion ultérieure ne peut améliorer cette heure), cela signifie
    que nous pouvons ignorer les connexions restantes. Cette optimisation réduit potentiellement une fois de plus le nombre d'itérations nécessaires afin de trouver le
    chemin optimal. En ce qui concerne la complexité, en prenant la complexité de base de l'algorithme, nous passons de $O(n)$ à $O(n - j)$ où $j$ est le nombre de 
    connexions que nous avons pu soustraire. Ceci nous permet une fois de plus d'avoir de meilleures performances globales.
    \item \textbf{Limited walking:} Une troisième optimisation que nous avons implémentée est la limitation du nombre et des distances des transferts à pied. 
    Nous parlons de la distance choisie et ce que cela apporte dans la section \hyperref[sec:walk]{2.3.1.} donc nous n'en reparlerons plus ici.
    Cela dit, nous aurions également pu implémenter une limite sur le nombre de transferts à pied. Sauf qu'en y ayant bien réfléchi, nous avons décidé de ne pas le faire car cela aurait
    pu amener à des chemins non optimaux et même impossibles pour des chemins demandant beaucoup de correspondances. En effet, si nous avions limité le nombre de transferts à pied,
    l'algorithme aurait pu trouver un chemin avec beaucoup de correspondances mais être dans l'impossibilité car il serait limité à un nombre de transferts à pied trop faible.
\end{itemize}

En somme, en assemblant nos deux optimisations, nous obtenons une complexité totale de $O(n - k - j)$ pour le coeur de l'algorithme \cite{dibbelt2017connection}.

\subsection{Chiffres concrets}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{graphique_traffique}
  \caption{Graphique du temps d'exécution en fonction de l'heure de départ.}
  \label{fig:graphique_traffique}
\end{figure}
De part ce graphe, nous pouvons voir que le temps d'exécution de l'algorithme est relativement constant jusqu'à 16 heures, puis grâce au \emph{Starting criterion},
l'algorithme devient de plus en plus rapide. En effet, à partir de 16 heures, il y a moins de connexions et il arrive a chaque fois à trouver le chemin optimal en mois d'une seconde.
Nous pouvons aussi parler du \emph{Stopping criterion}, qui lui permet de ne pas parcourir toutes les connexions et donc de ne pas perdre de temps à chercher des connexions inutiles.
Bien que nous ne puissions pas le voir sur le graphe, il est tout de même présent et permet de réduire le temps d'exécution de l'algorithme.

\subsection{Preuve du fonctionnement de l'algorithme}

Finalement, dans cette section concernant l'algorithme CSA, nous allons prouver sa véracité, pour chaque sommet $v$ accessible depuis une source $s$, une 
valeur $d(v)$ correspondant à la longueur d'un plus court chemin de $s$ à $v$. Pour cela, nous vérifions qu'il satisfait les trois conditions énoncées 
à la \emph{Proposition 26} trouvée dans le Syllabus d'algorithme 2, qui sont nécessaires et suffisantes \cite{syllabusAlgo2}.

\textbf{Proposition 26:} Soit $G = (V, \mathcal{E})$ un graphe orienté, pondéré positivement sur les arcs, $s \in V$ un sommet source, et une fonction 
d: V -> R.
On a:
\begin{enumerate}
    \item $d(s) = 0$;
    \item Pour tout sommet $v \in V$, $d(v)$ est la longueur d'un chemin de $s$ vers $v$;
    \item Pour tout arc $e = (u, v) \in \mathcal{E}$, $d(v) \leq d(u) + w(e)$.
\end{enumerate}

\noindent Démontrons maintenant que l'algorithme CSA vérifie chacune de ces conditions.

\paragraph{Condition 1:}
 $d(s) = 0$.
L'algorithme initialise, pour chaque arrêt de source $s$, l'heure d'arrivée à la valeur de départ $\tau_0$. On note:

$d(s)$:= $\tau_0$ - $\tau_0$ = 0.
Cela revient à poser $d(s)$ = 0 en considérant que le départ est à l'instant zéro. Cette condition est donc bien satisfaite.

\paragraph{Condition 2:} 
Pour tout sommet $v \in V$, $d(v)$ est la longueur d'un chemin de $s$ vers $v$.

\medskip

\textbf{Preuve:}
Par récurrence sur l'ordre topologique des sommets,
soit $v_1$, $v_2$, $\dots$, $v_n$ un ordre topologique de $G$. On note $P(v)$ un plus court chemin de $s$ vers $v$ découvert par l'algorithme.

\textbf{Cas de base:} $v_1 = s$. Par définition, $d(s) = 0$ et il existe un chemin trivial de $s$ à $s$ de longueur 0. La propriété est vraie.

\textbf{Démonstration:} Supposons que pour tout $v_i$ avec $i < k$, il existe un chemin $P(v_i)$ de $s$ à $v_i$ tel que $d(v_i)$ est la longueur de ce 
chemin. Considérons maintenant $v_k$. Par l'ordre topologique, tous les prédécesseurs $u$ de $v_k$ ont déjà été traités. Pour chaque arc $(u, v_k)$ $\in$ $\mathcal{E}$, l'algorithme met à jour:


$d(v_k)$ := $\min_{(u, v_k) \in \mathcal{E}}$ $\left\{ d(u) + w(u, v_k) \right\}$.


Par hypothèse de récurrence, pour chaque $u$, tel qu'il existe un chemin $P(u)$ de $s$ à $u$ de longueur $d(u)$. En ajoutant l'arc $(u, v_k)$, on obtient un chemin
$P(u) \cdot (u, v_k)$ de $s$ à $v_k$ de longueur $d(u) + w(u, v_k)$. Comme l'algorithme prend le minimum parmi tous ces chemins, il sélectionne l'un 
d'eux comme étant $P(v_k)$, un chemin effectif de $s$ à $v_k$, de longueur:

$d(v_k)$ = $\min_{(u, v_k) \in \mathcal{E}}$ $\left\{ d(u) + w(u, v_k) \right\}$.


Donc $d(v_k)$ est bien la longueur d'un chemin de $s$ vers $v_k$. Par conséquent, tout sommet $v$ possède un chemin de $s$ vers $v$ de 
longueur $d(v)$. La condition 2 est donc satisfaite.

\paragraph{Condition 3:}
Inégalité triangulaire $d(v)$ $\leq$ $d(u)$ + $w(e)$.
À chaque traitement d'un arc $e = (u, v)$ (d'une connexion $(u, v)$ avec un poids $w(e)$ égal à $\emph{connexion.getArrivalTime} - \emph{connexion.getDepartureTime}$),
l'algorithme vérifie si:\\
$d(v)$ > $d(u)$ + $w(e)$
et effectue la mise à jour dans ce cas. Une fois toutes les connexions traitées, aucune mise à jour n'est plus possible, ce qui implique:
$d(v) \leq d(u) + w(e),\quad \text{pour tout } (u, v) \in \mathcal{E}$.
Cela garantit que la fonction $d$ satisfait l'inégalité triangulaire pour tous les arcs du graphe.

\textbf{Fin de la preuve:} 
Les trois conditions de la Proposition~26 sont remplies par l'algorithme CSA. On en déduit que les valeurs $d(v)$ 
calculées représentent exactement les longueurs des plus courts chemins en temps du sommet $s$ vers tous les sommets atteignables dans le graphe.


\section{Classes utilisées}
Afin de clôturer ce rapport, revenons sur les classes utilisées dans notre code source afin de tout clarifier. À la section \hyperref[sec:init]{2}, nous expliquons
en détail les classes \hyperref[sec:route]{\emph{Route}}, \hyperref[sec:stoptime]{\emph{StopTime}}, \hyperref[sec:stop]{\emph{Stop}}, \hyperref[sec:trip]{\emph{Trip}},
\hyperref[sec:connexion]{\emph{Connexion}}, \hyperref[sec:balltree]{\emph{BallTree}} et, finalement, \hyperref[sec:walk]{\emph{Walk}}. Nous ne reviendrons donc pas sur
celles-ci.

Certaines classes ne sont que mentionnées dans les sections précédentes, à savoir les classes trouvées dans le dossier \emph{functional}.
\begin{itemize}
  \item \textbf{BinarySearch: } Une classe utilitaire possédant une unique méthode statique \emph{findStartIndex} permettant d'appliquer la première optimisation, c'est-à-dire
                                le \emph{Starting criterion}. Cette méthode est une implémentation de la recherche dichotomique.
  \item \textbf{Calculator: }   Une classe utilitaire possédant plusieurs méthodes statiques. Nous y trouvons d'abord \emph{haversine\_distance} permettant de calculer la distance entre deux arrêts
                                en utilisant la formule de Haversine. Ensuite, nous avons une série de méthodes de conversion temporelles, plus précisément des moyens de convertir un temps
                                en format \emph{HH:mm:ss} en secondes et inversement.
  \item \textbf{Initialiszer: } Une classe s'occupant de toute la partie initialisation des données. Elle possède une instance de la classe \emph{Parser} qui lit les fichiers CSV et les convertit
                                en objets Java et une instance de la classe \emph{Builder} qui, sur base des données chargées, construit les structures utiles à l'exécution du CSA.
  \item \textbf{Parser: }       Une classe s'occupant de la lecture des fichiers CSV et de la conversion de chaque ligne en objets Java. Elle est utilisée par la classe \emph{Initialiszer}.
  \item \textbf{Builder: }      Une classe s'occupant de la construction des objets Java à partir des données lues par la classe \emph{Parser}. Elle est utilisée par la classe \emph{Initialiszer}.
  \item \textbf{PathFinder: }   La pièce maîtresse du programme, elle contient la méthode \emph{findPath} implémentant l'algorithme CSA. D'autres méthodes annexes sont également trouvables comme
                                une méthode pour afficher un transfert à pied, ou une connexion. Nous soulignons la présence de la méthode \emph{findStopsByName} qui permet d'ajouter
                                la propriété multisource à notre algorithme, à savoir, pour un nom d'arrêts, nous récupérons tous les autres arrêts possédant ce nom.
\end{itemize} 

\section{Commentaires}
Au travers de ce rapport, nous avons justifé nos choix d'implémentation, de structures de données et autres d'un point de vue théorique et pratique. Nous avons développé et démontré
la complexité des étapes de notre programme et expliqué pourquoi celles-ci sont optimales. 

Suite à des conversations avec nos collègues étudiants suivies de recherches supplémentaires, nous nous sommes rendu compte que notre implémentation n'est pas la plus optimale. Nous
dédions donc cette section à souligner les défauts de notre implémentation et à expliquer comment nous aurions pu l'améliorer.

\subsection{Les requêtes de voisins}
L'utilisation du \emph{BallTree}, bien qu'amplement justifiée, n'est pas la plus optimale. En effet, le \emph{BallTree} est en fait une structure de données pour la recherche des
plus proches voisins adaptée pour des données de hautes dimensions. Dans notre cas, nous utilisons que deux dimensions, à savoir la latitude et la longitude. Certaines
alternatives plus intéressantes comme par exemple le \emph{R-Tree}, un arbre équilibré de recherche spatiale permettant une recherche plus rapide \cite{RTreedoc}.

\subsection{Le choix de l'algorithme}
Bien que le \emph{Connexion Scan Algorithm} soit rapide et simple à implémenter, nous avons constaté qu'il est peu adapté à la prise en compte de critères personnalisés autres que 
l'heure (comme le type de transport préféré). L'algorithme montre donc des limites en termes de flexibilité et de généricité.

Nous avons envisagé une piste consistant à ne construire que les connexions correspondant aux contraintes de l'utilisateur. Par exemple, si un utilisateur souhaite éviter les bus, 
il serait possible d'exclure toutes les connexions de ce type lors de l'initialisation. De même, les transferts à pied pourraient être générés avec un rayon réduit pour des utilisateurs
ne souhaitant pas marcher longtemps.

Nous n'avons pas poursuivi cette piste car celle-ci impliquait une modification au niveau de l'initialisation des données avec le point focal du projet étant l'aspect algorithmique.
Nous avons donc jugé cela non pertinent.

Afin de répondre à cette problématique, nous avons fait usage de \emph{flags} contenus en tant qu'attributs dans la classe \emph{PathFinder}. Ces \emph{flags} sont des booléens permettant
d'exclure certains types de connexions directement durant l'exécution de l'algorithme. L'utilisateur peut donc choisir s'il ne souhaite pas prendre le bus, le tram ou autres par exemple.

Malheureusement, cette solution ne répond pas à toutes les situations. Illustrons ceci par un exemple:

Un utilisateur souhaite se rendre d'un arrêt dense en services de transports à un arrêt éloigné peu desservi. En supposant que l'utilisateur ne souhaite pas prendre le train et 
que ces deux arrêts uniquement reliés par une ligne de train, l'algorithme ne trouvera pas de chemin.

Notre algorithme ne prend pas en compte le concept de `poids' et n'est donc pas complètement générique, mais nous avons tout de même cherché une solution comme décrit ci-dessus.



\section{Conclusion}
Ce projet nous a menés vers la découverte de nombreux concepts intéressants comme la recherche de voisins les plus proches à l'aide de différentes structures de données ainsi que
la recherche du plus court chemin au moyen de différents algorithmes. En particulier, l'algorithme \emph{Connexion Scan Algorithm}, choisi par nos soins afin de répondre à la
problématique proposée par ce projet est donc une solution rapide et efficace pour la recherche du plus court chemin sur base d'un ensemble de connexions. Cependant, au travers, d'échanges
et de recherches annexes, nous nous sommes rendu compte de certains défauts. Comme expliqué dans la section précédente, malgré sa facilité d'implémentation, il ne répond 
pas à l'ensemble de la problématique imposée. Nous tenions donc à souligner les défauts de  l'implémentation et les pistes d'amélioration possibles par souci de complétude et de transparence.


\section{Sources-bibliographie}
\printbibliography


\end{document}